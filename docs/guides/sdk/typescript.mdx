---
title: TypeScript SDK
description: Integrate Latitude into your Node.js applications using the TypeScript SDK.
---

The Latitude TypeScript SDK provides a convenient way to interact with the Latitude platform from your Node.js or browser applications.

## Installation

```bash
npm install @latitude/sdk
# or
yarn add @latitude/sdk
# or
pnpm add @latitude/sdk
```

## Authentication and Initialization

Import the client and initialize it with your API key. You can generate API keys in your Latitude project settings under "API Access".

```typescript
import { Latitude } from '@latitude/sdk'

const latitude = new Latitude(process.env.LATITUDE_API_KEY)
```

You can also provide additional options during initialization:

```typescript
const latitude = new Latitude(process.env.LATITUDE_API_KEY, {
  projectId: 123, // Your Latitude project ID
  versionUuid: 'version-uuid', // Optional version UUID
})
```

Keep your API key secure and avoid committing it directly into your codebase.

## SDK Structure

The Latitude SDK is organized into several namespaces:

- `prompts`: Methods for managing and running prompts
- `logs`: Methods for creating and managing logs
- `evaluations`: Methods for triggering evaluations and creating results

## Prompt Management

### Get a Prompt

To retrieve a specific prompt by its path:

```typescript
async function getPrompt(promptPath: string) {
  try {
    const prompt = await latitude.prompts.get(promptPath)
    console.log('Fetched Prompt:', prompt.name)
    return prompt
  } catch (error) {
    console.error(`Error fetching prompt ${promptPath}:`, error)
  }
}
```

### Get All Prompts

To retrieve all prompts in your project:

```typescript
async function getAllPrompts() {
  try {
    const prompts = await latitude.prompts.getAll()
    console.log(
      'Prompts:',
      prompts.map((p) => ({ id: p.id, name: p.name })),
    )
    return prompts
  } catch (error) {
    console.error('Error listing prompts:', error)
  }
}
```

### Get or Create a Prompt

To get an existing prompt or create a new one if it doesn't exist:

```typescript
async function getOrCreatePrompt(promptPath: string) {
  try {
    const prompt = await latitude.prompts.getOrCreate(promptPath)
    console.log('Prompt:', prompt.name)
    return prompt
  } catch (error) {
    console.error(`Error getting/creating prompt ${promptPath}:`, error)
  }
}
```

You can also provide a prompt object when creating a new prompt:

```typescript
async function createNewPrompt(promptPath: string) {
  try {
    const prompt = await latitude.prompts.getOrCreate(promptPath, {
      prompt: {
        name: 'My New Prompt',
        content: 'This is the content of my new prompt',
        provider: 'openai',
        // Other prompt properties...
      },
    })
    console.log('Created Prompt:', prompt.name)
    return prompt
  } catch (error) {
    console.error(`Error creating prompt ${promptPath}:`, error)
  }
}
```

## Running Prompts

### Standard Run (Non-Streaming)

Execute a prompt and get the complete response once generation is finished:

```typescript
async function runPrompt(promptPath: string) {
  try {
    const response = await latitude.prompts.run(promptPath, {
      parameters: {
        productName: 'CloudSync Pro',
        audience: 'Small Business Owners',
      },
      // Optional: Provide a custom identifier for this run
      customIdentifier: 'email-campaign-2023',
      // Optional: Provide callbacks for events
      onFinished: (data) => {
        console.log('Run complete:', data.uuid)
      },
      onError: (error) => {
        console.error('Run error:', error.message)
      },
    })

    console.log('Generated Content:')
    console.log(response.content)

    // Access response data
    console.log('Response UUID:', response.uuid)

    return response
  } catch (error) {
    console.error('Error running prompt:', error)
  }
}
```

### Handling Streaming Responses

For real-time applications (like chatbots), use streaming to get response chunks as they are generated:

```typescript
async function runStreamingPrompt(promptPath: string) {
  try {
    const stream = await latitude.prompts.run(promptPath, {
      parameters: {
        productName: 'CloudSync Pro',
        audience: 'Small Business Owners',
      },
      stream: true, // Enable streaming
      // Optional: Provide callbacks for events
      onEvent: ({ event, data }) => {
        console.log(`Received event: ${event}`, data)
      },
      onFinished: (data) => {
        console.log('Stream complete:', data.uuid)
      },
      onError: (error) => {
        console.error('Stream error:', error.message)
      },
    })

    console.log('Streaming Response:')
    let fullContent = ''
    for await (const chunk of stream) {
      // Process text chunks
      if (chunk.type === 'text-delta' && chunk.content) {
        process.stdout.write(chunk.content)
        fullContent += chunk.content
      }
      // Handle other event types (tool calls, errors, final response)
      if (chunk.type === 'response') {
        console.log(`\n--- Stream Finished ---`)
        console.log('Response UUID:', chunk.uuid)
        // Note: chunk.content might be empty here if streamed
      }
      // Add handling for chunk.type === 'tool-call', 'error', etc.
      // See Streaming Events guide for details: /guides/api/streaming-events
    }
    // fullContent now holds the complete generated text
  } catch (error) {
    console.error('Error running streaming prompt:', error)
  }
}
```

### Using Tools with Prompts

You can provide tool handlers that the model can call during execution:

```typescript
async function runPromptWithTools(promptPath: string) {
  try {
    const response = await latitude.prompts.run(promptPath, {
      parameters: {
        query: 'What is the weather in San Francisco?',
      },
      // Define tools the model can use
      tools: {
        getWeather: async (args, details) => {
          // args contains the arguments passed by the model
          // details contains context like toolId, toolName, etc.
          console.log('Getting weather for:', args.location)
          return { temperature: '72Â°F', conditions: 'Sunny' }
        },
      },
    })

    console.log('Response with tools:', response)
    return response
  } catch (error) {
    console.error('Error running prompt with tools:', error)
  }
}
```

### Chat with a Prompt

Start a chat conversation with a prompt:

```typescript
async function chatWithPrompt(promptUuid: string) {
  try {
    const messages = [
      {
        role: 'user',
        content: 'Hello, how can you help me today?',
      },
    ]

    const response = await latitude.prompts.chat(promptUuid, messages, {
      // Optional: Provide callbacks for events
      onFinished: (data) => {
        console.log('Chat complete:', data.uuid)
      },
      onError: (error) => {
        console.error('Chat error:', error.message)
      },
    })

    console.log('Chat Response:')
    console.log(response.content)

    return response
  } catch (error) {
    console.error('Error chatting with prompt:', error)
  }
}
```

### Rendering Prompts

#### Basic Rendering

Render a prompt without executing it:

```typescript
async function renderPrompt(prompt) {
  try {
    const result = await latitude.prompts.render({
      prompt: {
        content: 'Your prompt content here with {{parameters}}',
      },
      parameters: {
        topic: 'Artificial Intelligence',
        tone: 'Professional',
      },
      // Optional: Specify a provider adapter
      adapter: Adapters.OpenAI,
    })

    console.log('Rendered Messages:', result.messages)
    console.log('Rendered Config:', result.config)
    return result
  } catch (error) {
    console.error('Error rendering prompt:', error)
  }
}
```

#### Chain Rendering

Render a chain of prompts:

```typescript
async function renderChain(prompt) {
  try {
    const result = await latitude.prompts.renderChain({
      prompt: {
        path: '/path/to/prompt',
        content: 'Your prompt content here with {{parameters}}',
        provider: 'openai',
      },
      parameters: {
        topic: 'Machine Learning',
        complexity: 'Advanced',
      },
      // Required: Define how each step is processed
      onStep: async ({ messages, config }) => {
        // Process each step in the chain
        console.log('Processing step with messages:', messages)
        // Return string or message object
        return 'Step response'
      },
      // Optional: Log responses to Latitude
      logResponses: true,
      // Optional: Define tools for the chain
      tools: {
        getExample: async (args, details) => {
          return { example: 'This is an example response' }
        },
      },
    })

    console.log('Chain Rendering Result:', result)
    return result
  } catch (error) {
    console.error('Error rendering chain:', error)
  }
}
```

#### Rendering Agents

Render an agent prompt (similar to renderChain but with a result):

```typescript
async function renderAgent(prompt) {
  try {
    const result = await latitude.prompts.renderAgent({
      prompt: {
        path: '/path/to/agent-prompt',
        content: 'Agent prompt content with {{parameters}}',
        provider: 'openai',
      },
      parameters: {
        task: 'Research quantum computing',
        depth: 'Detailed',
      },
      // Required: Define how each step is processed
      onStep: async ({ messages, config }) => {
        // Process each step in the agent execution
        console.log('Processing agent step:', messages)
        return 'Agent step response'
      },
      // Optional: Log responses to Latitude
      logResponses: true,
      // Optional: Define tools for the agent
      tools: {
        search: async (args, details) => {
          console.log('Agent using search tool with args:', args)
          return { results: ['Result 1', 'Result 2'] }
        },
      },
    })

    console.log('Agent Rendering Result:', result)
    // Agent result is available in result.result
    console.log('Agent Final Result:', result.result)
    return result
  } catch (error) {
    console.error('Error rendering agent:', error)
  }
}
```

## Logging

### Creating Logs

Create a log entry for a prompt execution:

```typescript
async function createLog(promptPath: string, messages) {
  try {
    const log = await latitude.logs.create(promptPath, messages, {
      response: 'The response from the prompt execution',
      // Optional: Specify project ID and version UUID if different from initialization
      projectId: 123,
      versionUuid: 'version-uuid',
    })

    console.log('Created Log:', log.id)
    return log
  } catch (error) {
    console.error('Error creating log:', error)
  }
}
```

## Evaluations

### Triggering Evaluations

Trigger an evaluation for a conversation:

```typescript
async function triggerEvaluation(conversationUuid: string) {
  try {
    const result = await latitude.evaluations.trigger(conversationUuid, {
      evaluationUuids: ['eval-uuid-1', 'eval-uuid-2'], // Optional: specific evaluations to run
    })

    console.log('Evaluation Triggered:', result.uuid)
    return result
  } catch (error) {
    console.error('Error triggering evaluation:', error)
  }
}
```

### Creating Evaluation Results

Create a result for an evaluation:

```typescript
async function createEvaluationResult(
  conversationUuid: string,
  evaluationUuid: string,
) {
  try {
    const result = await latitude.evaluations.createResult(
      conversationUuid,
      evaluationUuid,
      {
        result: true, // Can be string, boolean, or number
        reason: 'The evaluation passed because...',
      },
    )

    console.log('Evaluation Result Created:', result.uuid)
    return result
  } catch (error) {
    console.error('Error creating evaluation result:', error)
  }
}
```

## Complete Method Reference

### Initialization

```typescript
// Basic initialization
const latitude = new Latitude(apiKey: string)

// Advanced initialization
const latitude = new Latitude(
  apiKey: string,
  options: {
    projectId?: number,
    versionUuid?: string,
    __internal?: {
      gateway?: GatewayApiConfig,
      source?: LogSources,
      retryMs?: number
    }
  }
)
```

### Prompts Namespace

```typescript
// Get a prompt
latitude.prompts.get(
  path: string,
  options?: {
    projectId?: number,
    versionUuid?: string
  }
): Promise<Prompt>

// Get all prompts
latitude.prompts.getAll(
  options?: {
    projectId?: number,
    versionUuid?: string
  }
): Promise<Prompt[]>

// Get or create a prompt
latitude.prompts.getOrCreate(
  path: string,
  options?: {
    projectId?: number,
    versionUuid?: string,
    prompt?: string
  }
): Promise<Prompt>

// Run a prompt
latitude.prompts.run<Tools extends ToolSpec = {}>(
  path: string,
  options: {
    projectId?: number,
    versionUuid?: string,
    customIdentifier?: string,
    parameters?: Record<string, unknown>,
    stream?: boolean,
    tools?: ToolCalledFn<Tools>,
    signal?: AbortSignal,
    onEvent?: ({ event, data }: { event: StreamEventTypes, data: ChainEventDto }) => void,
    onFinished?: (data: StreamChainResponse) => void,
    onError?: (error: LatitudeApiError) => void
  }
): Promise<(StreamChainResponse & { uuid: string }) | undefined>

// Chat with a prompt
latitude.prompts.chat<Tools extends ToolSpec = {}>(
  uuid: string,
  messages: Message[],
  options?: {
    stream?: boolean,
    tools?: ToolCalledFn<Tools>,
    signal?: AbortSignal,
    onEvent?: ({ event, data }: { event: StreamEventTypes, data: ChainEventDto }) => void,
    onFinished?: (data: StreamChainResponse) => void,
    onError?: (error: LatitudeApiError) => void
  }
): Promise<StreamChainResponse | undefined>

// Render a prompt
latitude.prompts.render<M extends AdapterMessageType = PromptlMessage>(
  options: {
    prompt: { content: string },
    parameters: Record<string, unknown>,
    adapter?: ProviderAdapter<M>
  }
): Promise<{ config: Config, messages: M[] }>

// Render a chain
latitude.prompts.renderChain<M extends AdapterMessageType = PromptlMessage>(
  options: {
    prompt: Prompt,
    parameters: Record<string, unknown>,
    adapter?: ProviderAdapter<M>,
    onStep: (args: { config: Config, messages: M[] }) => Promise<string | Omit<M, 'role'>>,
    tools?: RenderToolCalledFn<ToolSpec>,
    logResponses?: boolean
  }
): Promise<{ config: Config, messages: M[] }>

// Render an agent
latitude.prompts.renderAgent<M extends AdapterMessageType = PromptlMessage>(
  options: RenderChainOptions<M>
): Promise<{ config: Config, messages: M[], result: unknown }>
```

### Logs Namespace

```typescript
// Create a log
latitude.logs.create(
  path: string,
  messages: Message[],
  options?: {
    response?: string,
    projectId?: number,
    versionUuid?: string
  }
): Promise<DocumentLog>
```

### Evaluations Namespace

```typescript
// Trigger an evaluation
latitude.evaluations.trigger(
  uuid: string,
  options?: {
    evaluationUuids?: string[]
  }
): Promise<{ uuid: string }>

// Create an evaluation result
latitude.evaluations.createResult(
  uuid: string,
  evaluationUuid: string,
  options: {
    result: string | boolean | number,
    reason: string
  }
): Promise<{ uuid: string }>
```

## Error Handling

The SDK throws `LatitudeApiError` instances when API requests fail. You can catch and handle these errors:

```typescript
import { Latitude, LatitudeApiError } from '@latitude/sdk'

async function handleErrors() {
  try {
    const prompt = await latitude.prompts.get('non-existent-prompt')
  } catch (error) {
    if (error instanceof LatitudeApiError) {
      console.error('API Error:', error.message)
      console.error('Error Code:', error.errorCode)
      console.error('Status:', error.status)
    } else {
      console.error('Unexpected error:', error)
    }
  }
}
```

## Logging and Telemetry Features

- **Automatic Logging**: All runs through `latitude.prompts.run()` are automatically logged in Latitude, capturing inputs, outputs, performance metrics, and trace information.
- **Custom Identifiers**: Use the optional `customIdentifier` parameter to tag runs for easier filtering and analysis in the Latitude dashboard.
- **Response Data**: Each response includes identifying information like UUID that can be used to reference the specific run later.

## Further Information

- [HTTP API Reference](/guides/api/reference)
- [API Access and Authentication](/guides/api/api-access)
- [Streaming Event Details](/guides/api/streaming-events)
