---
title: Python SDK
description: Integrate Latitude into your Python applications using the Python SDK.
---

# Python SDK

The Latitude Python SDK allows you to easily interact with the Latitude platform from your Python applications.

## Installation

```bash
pip install latitude-sdk
```

## Requirements

Python 3.9 or higher is required to use the Latitude SDK.

## Authentication and Initialization

Import the SDK and initialize it with your API key. You can generate API keys in your Latitude project settings under "API Access".

```python
from latitude_sdk import Latitude, LatitudeOptions

# Basic initialization
sdk = Latitude("your-api-key-here")

# With additional options
sdk = Latitude("your-api-key-here", LatitudeOptions(
    project_id=12345,  # Your Latitude project ID
    version_uuid="optional-version-uuid",  # Optional version UUID
))
```

## SDK Structure

The Latitude SDK is organized into several namespaces:

- `prompts`: Methods for managing and running prompts
- `logs`: Methods for creating and managing logs
- `evaluations`: Methods for triggering evaluations and creating results

## Prompt Management

### Get a Prompt

To retrieve a specific prompt by its path:

```python
async def get_prompt(prompt_path):
    try:
        prompt = await sdk.prompts.get(prompt_path, GetPromptOptions(
            project_id=12345,  # Optional if provided at initialization
            version_uuid="optional-version-uuid"  # Optional
        ))
        print(f"Fetched Prompt: {prompt.name}")
        return prompt
    except Exception as error:
        print(f"Error fetching prompt {prompt_path}: {error}")
```

### Get All Prompts

To retrieve all prompts in your project:

```python
async def get_all_prompts():
    try:
        prompts = await sdk.prompts.get_all(GetAllPromptOptions(
            project_id=12345,  # Optional if provided at initialization
            version_uuid="optional-version-uuid"  # Optional
        ))
        print(f"Found {len(prompts)} prompts")
        return prompts
    except Exception as error:
        print(f"Error listing prompts: {error}")
```

### Get or Create a Prompt

To get an existing prompt or create a new one if it doesn't exist:

```python
from latitude_sdk import GetOrCreatePromptOptions

async def get_or_create_prompt(prompt_path):
    try:
        prompt = await sdk.prompts.get_or_create(prompt_path, GetOrCreatePromptOptions(
            project_id=12345,  # Optional if provided at initialization
            version_uuid="optional-version-uuid",  # Optional
            prompt="Content for the prompt if it needs to be created"  # Optional
        ))
        print(f"Prompt: {prompt.name}")
        return prompt
    except Exception as error:
        print(f"Error getting/creating prompt {prompt_path}: {error}")
```

## Running Prompts

### Standard Run (Non-Streaming)

Execute a prompt and get the complete response once generation is finished:

```python
from latitude_sdk import RunPromptOptions

async def run_prompt(prompt_path):
    try:
        response = await sdk.prompts.run(prompt_path, RunPromptOptions(
            parameters={
                "product_name": "CloudSync Pro",
                "audience": "Small Business Owners"
            },
            custom_identifier="marketing-campaign-2023",  # Optional: Provide a custom identifier
            project_id=12345,  # Optional if provided at initialization
            version_uuid="optional-version-uuid",  # Optional
            # Optional: Event callbacks
            on_finished=lambda data: print(f"Run complete: {data.uuid}"),
            on_error=lambda error: print(f"Run error: {error.message}")
        ))

        if response:
            print("Generated Content:")
            print(response.response.content)  # Access the response content
            print(f"Response UUID: {response.uuid}")

        return response
    except Exception as error:
        print(f"Error running prompt: {error}")
```

### Handling Streaming Responses

For real-time applications, use streaming to get response chunks as they're generated:

```python
async def run_streaming_prompt(prompt_path):
    try:
        response = await sdk.prompts.run(prompt_path, RunPromptOptions(
            parameters={
                "query": "Tell me about machine learning"
            },
            stream=True,  # Enable streaming
            # Event handlers
            on_event=lambda event: print(f"Received event: {event}"),
            on_finished=lambda data: print(f"Stream complete: {data.uuid}"),
            on_error=lambda error: print(f"Stream error: {error.message}")
        ))

        return response
    except Exception as error:
        print(f"Error running streaming prompt: {error}")
```

### Using Tools with Prompts

You can provide tool handlers that the model can call during execution:

```python
async def run_prompt_with_tools(prompt_path):
    try:
        response = await sdk.prompts.run(prompt_path, RunPromptOptions(
            parameters={
                "query": "What's the weather in San Francisco?"
            },
            # Define tools the model can use
            tools={
                "get_weather": async def(args, details):
                    # args contains the arguments passed by the model
                    # details contains context like tool_id, tool_name
                    print(f"Getting weather for: {args.get('location')}")
                    return {"temperature": "72Â°F", "conditions": "Sunny"}
            }
        ))

        return response
    except Exception as error:
        print(f"Error running prompt with tools: {error}")
```

### Chat with a Prompt

Continue a conversation with a prompt using its UUID:

```python
from latitude_sdk import ChatPromptOptions

async def chat_with_prompt(prompt_uuid):
    try:
        messages = [
            {"role": "user", "content": "Hello, how can you help me today?"}
        ]

        response = await sdk.prompts.chat(prompt_uuid, messages, ChatPromptOptions(
            # Optional: Event callbacks
            on_finished=lambda data: print(f"Chat complete: {data.uuid}"),
            on_error=lambda error: print(f"Chat error: {error.message}"),
            # Optional: Enable streaming
            stream=True,
            # Optional: Define tools
            tools={
                "search": async def(args, details):
                    return {"results": ["Result 1", "Result 2"]}
            }
        ))

        if response:
            print("Chat Response:")
            print(response.response.content)

        return response
    except Exception as error:
        print(f"Error chatting with prompt: {error}")
```

### Rendering Prompts

#### Basic Rendering

Render a prompt without executing it through Latitude's services:

```python
from latitude_sdk import RenderPromptOptions
from promptl_ai import Adapter

async def render_prompt(prompt_content):
    try:
        result = await sdk.prompts.render(prompt_content, RenderPromptOptions(
            parameters={
                "topic": "Artificial Intelligence",
                "tone": "Professional"
            },
            adapter=Adapter.OpenAI  # Optional: Specify an adapter (OpenAI is default)
        ))

        print("Rendered Messages:", result.messages)
        print("Rendered Config:", result.config)
        return result
    except Exception as error:
        print(f"Error rendering prompt: {error}")
```

#### Chain Rendering

Render a chain of prompts:

```python
from latitude_sdk import RenderChainOptions, GetPromptOptions, Prompt

async def render_chain_example(prompt_path: str):
    try:
        # First, fetch the Prompt object
        latitude_prompt: Prompt = await sdk.prompts.get(prompt_path, GetPromptOptions(project_id=12345))

        async def on_step(messages, config):
            # Process each step in the chain
            print("Processing step with messages:", messages)
            # Return a string or message object
            return "Step response"

        result = await sdk.prompts.render_chain(
            latitude_prompt, # Pass the fetched Prompt object
            on_step,
            RenderChainOptions(
                parameters={
                    "topic": "Machine Learning",
                    "complexity": "Advanced"
                }
            )
        )

        print("Chain Rendering Result:", result)
        return result
    except Exception as error:
        print(f"Error rendering chain: {error}")
```

## Logging

### Creating Logs

Create a log entry for a prompt execution:

```python
from latitude_sdk import CreateLogOptions

async def create_log(prompt_path, messages):
    try:
        log = await sdk.logs.create(prompt_path, messages, CreateLogOptions(
            response="The response from the prompt execution",
            project_id=12345,  # Optional if provided at initialization
            version_uuid="optional-version-uuid"  # Optional
        ))

        print(f"Created Log: {log.id}")
        return log
    except Exception as error:
        print(f"Error creating log: {error}")
```

## Evaluations

### Triggering Evaluations

Trigger an evaluation for a conversation:

```python
from latitude_sdk import TriggerEvaluationOptions

async def trigger_evaluation(conversation_uuid):
    try:
        result = await sdk.evaluations.trigger(conversation_uuid, TriggerEvaluationOptions(
            evaluation_uuids=["eval-uuid-1", "eval-uuid-2"]  # Optional: specific evaluations to run
        ))

        print(f"Evaluations Triggered: {result.evaluations}")
        return result
    except Exception as error:
        print(f"Error triggering evaluation: {error}")
```

### Creating Evaluation Results

Create a result for an evaluation:

```python
from latitude_sdk import CreateEvaluationResultOptions

async def create_evaluation_result(conversation_uuid, evaluation_uuid):
    try:
        result = await sdk.evaluations.create_result(
            conversation_uuid,
            evaluation_uuid,
            CreateEvaluationResultOptions(
                result=True,  # Can be string, boolean, or number
                reason="The evaluation passed because..."
            )
        )

        print(f"Evaluation Result Created: {result.uuid}")
        return result
    except Exception as error:
        print(f"Error creating evaluation result: {error}")
```

## Error Handling

The SDK throws `ApiError` instances when API requests fail:

```python
from latitude_sdk import ApiError, ApiErrorCodes

async def handle_errors():
    try:
        prompt = await sdk.prompts.get("non-existent-prompt")
    except ApiError as error:
        print(f"API Error: {error.message}")
        print(f"Error Code: {error.code}")
        print(f"Status: {error.status}")
    except Exception as error:
        print(f"Unexpected error: {error}")
```

## Logging and Telemetry Features

- **Automatic Logging**: All runs through `sdk.prompts.run()` are automatically logged in Latitude, capturing inputs, outputs, performance metrics, and trace information.
- **Custom Identifiers**: Use the optional `custom_identifier` parameter to tag runs for easier filtering and analysis in the Latitude dashboard.
- **Response Data**: Each response includes identifying information like UUID that can be used to reference the specific run later.

## Further Information

- [HTTP API Reference](/guides/api/reference)
- [API Access and Authentication](/guides/api/api-access)
- [Streaming Event Details](/guides/api/streaming-events)
